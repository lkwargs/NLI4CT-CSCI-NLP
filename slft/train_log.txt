/home/josep/miniconda3/envs/nlp/lib/python3.11/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.
  warnings.warn(
/home/josep/miniconda3/envs/nlp/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:472: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:13<00:00,  6.74s/it]
Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 1700/1700 [00:00<00:00, 7070.36 examples/s]
  0%|                                                                                                                             | 0/636 [00:00<?, ?it/s]You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
/home/josep/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/josep/miniconda3/envs/nlp/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
/home/josep/miniconda3/envs/nlp/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 2.1702, 'learning_rate': 1.4077830188679245e-05, 'epoch': 0.0}                                                                                   
{'loss': 2.349, 'learning_rate': 1.4055660377358491e-05, 'epoch': 0.01}                                                                                   
{'loss': 2.0553, 'learning_rate': 1.4033490566037736e-05, 'epoch': 0.01}                                                                                  
{'loss': 1.8714, 'learning_rate': 1.4011320754716982e-05, 'epoch': 0.02}                                                                                  
{'loss': 2.1839, 'learning_rate': 1.3989150943396226e-05, 'epoch': 0.02}                                                                                  
{'loss': 2.0233, 'learning_rate': 1.3966981132075472e-05, 'epoch': 0.03}                                                                                  
{'loss': 2.1044, 'learning_rate': 1.3944811320754717e-05, 'epoch': 0.03}                                                                                  
{'loss': 2.5155, 'learning_rate': 1.3922641509433963e-05, 'epoch': 0.04}                                                                                  
{'loss': 2.0312, 'learning_rate': 1.3900471698113207e-05, 'epoch': 0.04}                                                                                  
{'loss': 2.1738, 'learning_rate': 1.3878301886792454e-05, 'epoch': 0.05}                                                                                  
{'loss': 2.3694, 'learning_rate': 1.3856132075471698e-05, 'epoch': 0.05}                                                                                  
{'loss': 2.0513, 'learning_rate': 1.3833962264150944e-05, 'epoch': 0.06}                                                                                  
{'loss': 2.1115, 'learning_rate': 1.3811792452830189e-05, 'epoch': 0.06}                                                                                  
{'loss': 2.2279, 'learning_rate': 1.3789622641509435e-05, 'epoch': 0.07}                                                                                  
{'loss': 1.8889, 'learning_rate': 1.376745283018868e-05, 'epoch': 0.07}                                                                                   
{'loss': 1.9889, 'learning_rate': 1.3745283018867925e-05, 'epoch': 0.08}                                                                                  
{'loss': 2.1479, 'learning_rate': 1.372311320754717e-05, 'epoch': 0.08}                                                                                   
{'loss': 1.9317, 'learning_rate': 1.3700943396226416e-05, 'epoch': 0.08}                                                                                  
{'loss': 2.147, 'learning_rate': 1.367877358490566e-05, 'epoch': 0.09}                                                                                    
{'loss': 2.2481, 'learning_rate': 1.3656603773584907e-05, 'epoch': 0.09}                                                                                  
{'loss': 2.0026, 'learning_rate': 1.3634433962264151e-05, 'epoch': 0.1}                                                                                   
{'loss': 2.1692, 'learning_rate': 1.3612264150943397e-05, 'epoch': 0.1}                                                                                   
{'loss': 1.7582, 'learning_rate': 1.3590094339622642e-05, 'epoch': 0.11}                                                                                  
{'loss': 2.5683, 'learning_rate': 1.3567924528301888e-05, 'epoch': 0.11}                                                                                  
{'loss': 2.4671, 'learning_rate': 1.3545754716981132e-05, 'epoch': 0.12}                                                                                  
{'loss': 2.3468, 'learning_rate': 1.3523584905660378e-05, 'epoch': 0.12}                                                                                  
{'loss': 2.154, 'learning_rate': 1.3501415094339623e-05, 'epoch': 0.13}                                                                                   
{'loss': 2.4585, 'learning_rate': 1.3479245283018869e-05, 'epoch': 0.13}                                                                                  
{'loss': 2.2838, 'learning_rate': 1.3457075471698113e-05, 'epoch': 0.14}                                                                                  
{'loss': 1.7322, 'learning_rate': 1.343490566037736e-05, 'epoch': 0.14}                                                                                   
{'loss': 1.6083, 'learning_rate': 1.3412735849056604e-05, 'epoch': 0.15}                                                                                  
{'loss': 1.8766, 'learning_rate': 1.339056603773585e-05, 'epoch': 0.15}                                                                                   
{'loss': 2.1892, 'learning_rate': 1.3368396226415095e-05, 'epoch': 0.16}                                                                                  
{'loss': 1.9762, 'learning_rate': 1.334622641509434e-05, 'epoch': 0.16}                                                                                   
{'loss': 1.8365, 'learning_rate': 1.3324056603773585e-05, 'epoch': 0.16}                                                                                  
{'loss': 1.7717, 'learning_rate': 1.3301886792452831e-05, 'epoch': 0.17}                                                                                  
{'loss': 2.4011, 'learning_rate': 1.3279716981132076e-05, 'epoch': 0.17}                                                                                  
{'loss': 1.6928, 'learning_rate': 1.3257547169811322e-05, 'epoch': 0.18}                                                                                  
{'loss': 1.8906, 'learning_rate': 1.3235377358490567e-05, 'epoch': 0.18}                                                                                  
{'loss': 2.1955, 'learning_rate': 1.3213207547169813e-05, 'epoch': 0.19}                                                                                  
{'loss': 1.797, 'learning_rate': 1.3191037735849057e-05, 'epoch': 0.19}                                                                                   
{'loss': 1.84, 'learning_rate': 1.3168867924528303e-05, 'epoch': 0.2}                                                                                     
{'loss': 2.3285, 'learning_rate': 1.3146698113207548e-05, 'epoch': 0.2}                                                                                   
{'loss': 2.017, 'learning_rate': 1.3124528301886794e-05, 'epoch': 0.21}                                                                                   
{'loss': 1.787, 'learning_rate': 1.3102358490566038e-05, 'epoch': 0.21}                                                                                   
{'loss': 2.3206, 'learning_rate': 1.3080188679245284e-05, 'epoch': 0.22}                                                                                  
{'loss': 1.9219, 'learning_rate': 1.3058018867924529e-05, 'epoch': 0.22}                                                                                  
{'loss': 1.5287, 'learning_rate': 1.3035849056603775e-05, 'epoch': 0.23}                                                                                  
{'loss': 1.9443, 'learning_rate': 1.301367924528302e-05, 'epoch': 0.23}                                                                                   
{'loss': 1.8414, 'learning_rate': 1.2991509433962266e-05, 'epoch': 0.24}                                                                                  
{'loss': 1.7085, 'learning_rate': 1.296933962264151e-05, 'epoch': 0.24}                                                                                   
{'loss': 1.7435, 'learning_rate': 1.2947169811320755e-05, 'epoch': 0.24}                                                                                  
{'loss': 2.0133, 'learning_rate': 1.2925e-05, 'epoch': 0.25}                                                                                              
{'loss': 1.7627, 'learning_rate': 1.2902830188679245e-05, 'epoch': 0.25}                                                                                  
{'loss': 1.8222, 'learning_rate': 1.2880660377358491e-05, 'epoch': 0.26}                                                                                  
{'loss': 1.4478, 'learning_rate': 1.2858490566037736e-05, 'epoch': 0.26}                                                                                  
{'loss': 2.0336, 'learning_rate': 1.283632075471698e-05, 'epoch': 0.27}                                                                                   
{'loss': 2.1023, 'learning_rate': 1.2814150943396226e-05, 'epoch': 0.27}                                                                                  
{'loss': 1.5596, 'learning_rate': 1.2791981132075471e-05, 'epoch': 0.28}                                                                                  
{'loss': 2.0258, 'learning_rate': 1.2769811320754717e-05, 'epoch': 0.28}                                                                                  
{'loss': 1.8695, 'learning_rate': 1.2747641509433961e-05, 'epoch': 0.29}                                                                                  
{'loss': 1.7546, 'learning_rate': 1.2725471698113208e-05, 'epoch': 0.29}                                                                                  
{'loss': 1.5093, 'learning_rate': 1.2703301886792452e-05, 'epoch': 0.3}                                                                                   
{'loss': 1.8626, 'learning_rate': 1.2681132075471698e-05, 'epoch': 0.3}                                                                                   
{'loss': 1.6638, 'learning_rate': 1.2658962264150943e-05, 'epoch': 0.31}                                                                                  
{'loss': 1.6554, 'learning_rate': 1.2636792452830189e-05, 'epoch': 0.31}                                                                                  
{'loss': 1.608, 'learning_rate': 1.2614622641509433e-05, 'epoch': 0.32}                                                                                   
{'loss': 1.6949, 'learning_rate': 1.259245283018868e-05, 'epoch': 0.32}                                                                                   
{'loss': 1.7165, 'learning_rate': 1.2570283018867924e-05, 'epoch': 0.32}                                                                                  
{'loss': 1.7627, 'learning_rate': 1.254811320754717e-05, 'epoch': 0.33}                                                                                   
{'loss': 1.81, 'learning_rate': 1.2525943396226415e-05, 'epoch': 0.33}                                                                                    
{'loss': 1.6612, 'learning_rate': 1.250377358490566e-05, 'epoch': 0.34}                                                                                   
{'loss': 1.5556, 'learning_rate': 1.2481603773584905e-05, 'epoch': 0.34}                                                                                  
{'loss': 1.6015, 'learning_rate': 1.2459433962264151e-05, 'epoch': 0.35}                                                                                  
{'loss': 1.7473, 'learning_rate': 1.2437264150943396e-05, 'epoch': 0.35}                                                                                  
{'loss': 1.7578, 'learning_rate': 1.2415094339622642e-05, 'epoch': 0.36}                                                                                  
{'loss': 1.8261, 'learning_rate': 1.2392924528301886e-05, 'epoch': 0.36}                                                                                  
{'loss': 1.7885, 'learning_rate': 1.2370754716981133e-05, 'epoch': 0.37}                                                                                  
{'loss': 1.6268, 'learning_rate': 1.2348584905660377e-05, 'epoch': 0.37}                                                                                  
{'loss': 1.6595, 'learning_rate': 1.2326415094339623e-05, 'epoch': 0.38}                                                                                  
{'loss': 1.6813, 'learning_rate': 1.2304245283018868e-05, 'epoch': 0.38}                                                                                  
{'loss': 1.5924, 'learning_rate': 1.2282075471698114e-05, 'epoch': 0.39}                                                                                  
{'loss': 1.6327, 'learning_rate': 1.2259905660377358e-05, 'epoch': 0.39}                                                                                  
{'loss': 1.7884, 'learning_rate': 1.2237735849056604e-05, 'epoch': 0.4}                                                                                   
{'loss': 1.7341, 'learning_rate': 1.2215566037735849e-05, 'epoch': 0.4}                                                                                   
{'loss': 1.905, 'learning_rate': 1.2193396226415095e-05, 'epoch': 0.4}                                                                                    
{'loss': 1.6038, 'learning_rate': 1.217122641509434e-05, 'epoch': 0.41}                                                                                   
{'loss': 1.5193, 'learning_rate': 1.2149056603773586e-05, 'epoch': 0.41}                                                                                  
{'loss': 1.802, 'learning_rate': 1.212688679245283e-05, 'epoch': 0.42}                                                                                    
{'loss': 1.6754, 'learning_rate': 1.2104716981132076e-05, 'epoch': 0.42}                                                                                  
{'loss': 1.5367, 'learning_rate': 1.208254716981132e-05, 'epoch': 0.43}                                                                                   
{'loss': 1.3605, 'learning_rate': 1.2060377358490567e-05, 'epoch': 0.43}                                                                                  
{'loss': 1.7347, 'learning_rate': 1.2038207547169811e-05, 'epoch': 0.44}                                                                                  
{'loss': 1.7365, 'learning_rate': 1.2016037735849057e-05, 'epoch': 0.44}                                                                                  
{'loss': 1.2626, 'learning_rate': 1.1993867924528302e-05, 'epoch': 0.45}                                                                                  
{'loss': 1.7138, 'learning_rate': 1.1971698113207548e-05, 'epoch': 0.45}                                                                                  
{'loss': 1.9832, 'learning_rate': 1.1949528301886792e-05, 'epoch': 0.46}                                                                                  
{'loss': 1.449, 'learning_rate': 1.1927358490566039e-05, 'epoch': 0.46}                                                                                   
{'loss': 1.7132, 'learning_rate': 1.1905188679245283e-05, 'epoch': 0.47}                                                                                  
{'loss': 1.6153, 'learning_rate': 1.188301886792453e-05, 'epoch': 0.47}                                                                                   
 16%|██████████████████                                                                                                 | 100/636 [08:37<38:14,  4.28s/it]/home/josep/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/josep/miniconda3/envs/nlp/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
/home/josep/miniconda3/envs/nlp/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 1.5222, 'learning_rate': 1.1860849056603774e-05, 'epoch': 0.48}                                                                                  
{'loss': 1.3295, 'learning_rate': 1.183867924528302e-05, 'epoch': 0.48}                                                                                   
{'loss': 1.8742, 'learning_rate': 1.1816509433962264e-05, 'epoch': 0.48}                                                                                  
{'loss': 1.5761, 'learning_rate': 1.179433962264151e-05, 'epoch': 0.49}                                                                                   
{'loss': 1.3599, 'learning_rate': 1.1772169811320755e-05, 'epoch': 0.49}                                                                                  
{'loss': 1.5944, 'learning_rate': 1.1750000000000001e-05, 'epoch': 0.5}                                                                                   
{'loss': 1.531, 'learning_rate': 1.1727830188679245e-05, 'epoch': 0.5}                                                                                    
{'loss': 1.7939, 'learning_rate': 1.1705660377358492e-05, 'epoch': 0.51}                                                                                  
{'loss': 1.8039, 'learning_rate': 1.1683490566037736e-05, 'epoch': 0.51}                                                                                  
{'loss': 1.4098, 'learning_rate': 1.1661320754716982e-05, 'epoch': 0.52}                                                                                  
{'loss': 1.7985, 'learning_rate': 1.1639150943396227e-05, 'epoch': 0.52}                                                                                  
{'loss': 1.6174, 'learning_rate': 1.1616981132075473e-05, 'epoch': 0.53}                                                                                  
{'loss': 1.8173, 'learning_rate': 1.1594811320754717e-05, 'epoch': 0.53}                                                                                  
{'loss': 1.5334, 'learning_rate': 1.1572641509433963e-05, 'epoch': 0.54}                                                                                  
{'loss': 1.5547, 'learning_rate': 1.1550471698113208e-05, 'epoch': 0.54}                                                                                  
{'loss': 1.4587, 'learning_rate': 1.1528301886792454e-05, 'epoch': 0.55}                                                                                  
{'loss': 1.9041, 'learning_rate': 1.1506132075471698e-05, 'epoch': 0.55}                                                                                  
{'loss': 1.5009, 'learning_rate': 1.1483962264150945e-05, 'epoch': 0.56}                                                                                  
{'loss': 1.5974, 'learning_rate': 1.1461792452830189e-05, 'epoch': 0.56}                                                                                  
{'loss': 1.6029, 'learning_rate': 1.1439622641509435e-05, 'epoch': 0.56}                                                                                  
{'loss': 1.7064, 'learning_rate': 1.141745283018868e-05, 'epoch': 0.57}                                                                                   
{'loss': 1.6161, 'learning_rate': 1.1395283018867926e-05, 'epoch': 0.57}                                                                                  
{'loss': 1.5931, 'learning_rate': 1.137311320754717e-05, 'epoch': 0.58}                                                                                   
{'loss': 1.5408, 'learning_rate': 1.1350943396226416e-05, 'epoch': 0.58}                                                                                  
{'loss': 1.2673, 'learning_rate': 1.1328773584905661e-05, 'epoch': 0.59}                                                                                  
{'loss': 1.6489, 'learning_rate': 1.1306603773584907e-05, 'epoch': 0.59}                                                                                  
{'loss': 1.4858, 'learning_rate': 1.1284433962264152e-05, 'epoch': 0.6}                                                                                   
{'loss': 1.513, 'learning_rate': 1.1262264150943398e-05, 'epoch': 0.6}                                                                                    
{'loss': 1.6966, 'learning_rate': 1.1240094339622642e-05, 'epoch': 0.61}                                                                                  
{'loss': 1.6094, 'learning_rate': 1.1217924528301888e-05, 'epoch': 0.61}                                                                                  
{'loss': 1.5272, 'learning_rate': 1.1195754716981133e-05, 'epoch': 0.62}                                                                                  
{'loss': 1.547, 'learning_rate': 1.1173584905660379e-05, 'epoch': 0.62}                                                                                   
{'loss': 1.614, 'learning_rate': 1.1151415094339623e-05, 'epoch': 0.63}                                                                                   
{'loss': 1.4455, 'learning_rate': 1.112924528301887e-05, 'epoch': 0.63}                                                                                   
{'loss': 1.6584, 'learning_rate': 1.1107075471698114e-05, 'epoch': 0.64}                                                                                  
{'loss': 1.2685, 'learning_rate': 1.108490566037736e-05, 'epoch': 0.64}                                                                                   
{'loss': 1.454, 'learning_rate': 1.1062735849056605e-05, 'epoch': 0.64}                                                                                   
{'loss': 1.6458, 'learning_rate': 1.104056603773585e-05, 'epoch': 0.65}                                                                                   
{'loss': 1.3009, 'learning_rate': 1.1018396226415095e-05, 'epoch': 0.65}                                                                                  
{'loss': 1.6861, 'learning_rate': 1.0996226415094341e-05, 'epoch': 0.66}                                                                                  
{'loss': 1.3709, 'learning_rate': 1.0974056603773586e-05, 'epoch': 0.66}                                                                                  
{'loss': 1.3539, 'learning_rate': 1.0951886792452832e-05, 'epoch': 0.67}                                                                                  
{'loss': 1.4004, 'learning_rate': 1.0929716981132076e-05, 'epoch': 0.67}                                                                                  
{'loss': 1.5047, 'learning_rate': 1.0907547169811323e-05, 'epoch': 0.68}                                                                                  
{'loss': 1.3175, 'learning_rate': 1.0885377358490567e-05, 'epoch': 0.68}                                                                                  
{'loss': 1.4569, 'learning_rate': 1.0863207547169813e-05, 'epoch': 0.69}                                                                                  
{'loss': 1.2377, 'learning_rate': 1.0841037735849058e-05, 'epoch': 0.69}                                                                                  
{'loss': 1.4414, 'learning_rate': 1.0818867924528304e-05, 'epoch': 0.7}                                                                                   
{'loss': 1.4198, 'learning_rate': 1.0796698113207548e-05, 'epoch': 0.7}                                                                                   
{'loss': 1.4553, 'learning_rate': 1.0774528301886794e-05, 'epoch': 0.71}                                                                                  
{'loss': 1.2543, 'learning_rate': 1.0752358490566039e-05, 'epoch': 0.71}                                                                                  
{'loss': 1.5172, 'learning_rate': 1.0730188679245285e-05, 'epoch': 0.72}                                                                                  
{'loss': 1.4672, 'learning_rate': 1.070801886792453e-05, 'epoch': 0.72}                                                                                   
{'loss': 1.3816, 'learning_rate': 1.0685849056603776e-05, 'epoch': 0.72}                                                                                  
{'loss': 1.5652, 'learning_rate': 1.066367924528302e-05, 'epoch': 0.73}                                                                                   
{'loss': 1.61, 'learning_rate': 1.0641509433962264e-05, 'epoch': 0.73}                                                                                    
{'loss': 1.2573, 'learning_rate': 1.061933962264151e-05, 'epoch': 0.74}                                                                                   
{'loss': 1.2555, 'learning_rate': 1.0597169811320755e-05, 'epoch': 0.74}                                                                                  
{'loss': 1.4511, 'learning_rate': 1.0575e-05, 'epoch': 0.75}                                                                                              
{'loss': 1.4873, 'learning_rate': 1.0552830188679246e-05, 'epoch': 0.75}                                                                                  
{'loss': 1.547, 'learning_rate': 1.053066037735849e-05, 'epoch': 0.76}                                                                                    
{'loss': 1.289, 'learning_rate': 1.0508490566037736e-05, 'epoch': 0.76}                                                                                   
{'loss': 1.3958, 'learning_rate': 1.048632075471698e-05, 'epoch': 0.77}                                                                                   
{'loss': 1.1928, 'learning_rate': 1.0464150943396225e-05, 'epoch': 0.77}                                                                                  
{'loss': 1.4299, 'learning_rate': 1.0441981132075471e-05, 'epoch': 0.78}                                                                                  
{'loss': 1.422, 'learning_rate': 1.0419811320754716e-05, 'epoch': 0.78}                                                                                   
{'loss': 1.1515, 'learning_rate': 1.0397641509433962e-05, 'epoch': 0.79}                                                                                  
{'loss': 1.3375, 'learning_rate': 1.0375471698113206e-05, 'epoch': 0.79}                                                                                  
{'loss': 1.4732, 'learning_rate': 1.0353301886792453e-05, 'epoch': 0.8}                                                                                   
{'loss': 1.1661, 'learning_rate': 1.0331132075471697e-05, 'epoch': 0.8}                                                                                   
{'loss': 1.3784, 'learning_rate': 1.0308962264150943e-05, 'epoch': 0.8}                                                                                   
{'loss': 1.5121, 'learning_rate': 1.0286792452830188e-05, 'epoch': 0.81}                                                                                  
{'loss': 1.4663, 'learning_rate': 1.0264622641509434e-05, 'epoch': 0.81}                                                                                  
{'loss': 1.4653, 'learning_rate': 1.0242452830188678e-05, 'epoch': 0.82}                                                                                  
{'loss': 1.4484, 'learning_rate': 1.0220283018867924e-05, 'epoch': 0.82}                                                                                  
{'loss': 1.532, 'learning_rate': 1.0198113207547169e-05, 'epoch': 0.83}                                                                                   
{'loss': 1.3027, 'learning_rate': 1.0175943396226415e-05, 'epoch': 0.83}                                                                                  
{'loss': 1.2395, 'learning_rate': 1.015377358490566e-05, 'epoch': 0.84}                                                                                   
{'loss': 1.41, 'learning_rate': 1.0131603773584906e-05, 'epoch': 0.84}                                                                                    
{'loss': 1.3575, 'learning_rate': 1.010943396226415e-05, 'epoch': 0.85}                                                                                   
{'loss': 1.4257, 'learning_rate': 1.0087264150943396e-05, 'epoch': 0.85}                                                                                  
{'loss': 1.2384, 'learning_rate': 1.006509433962264e-05, 'epoch': 0.86}                                                                                   
{'loss': 1.2652, 'learning_rate': 1.0042924528301887e-05, 'epoch': 0.86}                                                                                  
{'loss': 1.2284, 'learning_rate': 1.0020754716981131e-05, 'epoch': 0.87}                                                                                  
{'loss': 1.3374, 'learning_rate': 9.998584905660377e-06, 'epoch': 0.87}                                                                                   
{'loss': 1.4548, 'learning_rate': 9.976415094339622e-06, 'epoch': 0.88}                                                                                   
{'loss': 1.2805, 'learning_rate': 9.954245283018868e-06, 'epoch': 0.88}                                                                                   
{'loss': 1.355, 'learning_rate': 9.932075471698113e-06, 'epoch': 0.88}                                                                                    
{'loss': 1.0004, 'learning_rate': 9.909905660377359e-06, 'epoch': 0.89}                                                                                   
{'loss': 1.2327, 'learning_rate': 9.887735849056603e-06, 'epoch': 0.89}                                                                                   
{'loss': 1.2469, 'learning_rate': 9.86556603773585e-06, 'epoch': 0.9}                                                                                     
{'loss': 1.3635, 'learning_rate': 9.843396226415094e-06, 'epoch': 0.9}                                                                                    
{'loss': 1.253, 'learning_rate': 9.82122641509434e-06, 'epoch': 0.91}                                                                                     
{'loss': 1.3563, 'learning_rate': 9.799056603773584e-06, 'epoch': 0.91}                                                                                   
{'loss': 1.237, 'learning_rate': 9.77688679245283e-06, 'epoch': 0.92}                                                                                     
{'loss': 1.1348, 'learning_rate': 9.754716981132075e-06, 'epoch': 0.92}                                                                                   
{'loss': 1.115, 'learning_rate': 9.732547169811321e-06, 'epoch': 0.93}                                                                                    
{'loss': 1.2908, 'learning_rate': 9.710377358490566e-06, 'epoch': 0.93}                                                                                   
{'loss': 1.2218, 'learning_rate': 9.688207547169812e-06, 'epoch': 0.94}                                                                                   
{'loss': 1.2179, 'learning_rate': 9.666037735849056e-06, 'epoch': 0.94}                                                                                   
 31%|████████████████████████████████████▏                                                                              | 200/636 [17:07<42:34,  5.86s/it]/home/josep/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/josep/miniconda3/envs/nlp/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
/home/josep/miniconda3/envs/nlp/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 1.2031, 'learning_rate': 9.643867924528302e-06, 'epoch': 0.95}                                                                                   
{'loss': 1.3862, 'learning_rate': 9.621698113207547e-06, 'epoch': 0.95}                                                                                   
{'loss': 1.3651, 'learning_rate': 9.599528301886793e-06, 'epoch': 0.96}                                                                                   
{'loss': 1.1623, 'learning_rate': 9.577358490566037e-06, 'epoch': 0.96}                                                                                   
{'loss': 1.1918, 'learning_rate': 9.555188679245284e-06, 'epoch': 0.96}                                                                                   
{'loss': 1.272, 'learning_rate': 9.533018867924528e-06, 'epoch': 0.97}                                                                                    
{'loss': 1.1626, 'learning_rate': 9.510849056603774e-06, 'epoch': 0.97}                                                                                   
{'loss': 1.3837, 'learning_rate': 9.488679245283019e-06, 'epoch': 0.98}                                                                                   
{'loss': 1.0158, 'learning_rate': 9.466509433962265e-06, 'epoch': 0.98}                                                                                   
{'loss': 1.4685, 'learning_rate': 9.44433962264151e-06, 'epoch': 0.99}                                                                                    
{'loss': 1.4273, 'learning_rate': 9.422169811320755e-06, 'epoch': 0.99}                                                                                   
{'loss': 1.0762, 'learning_rate': 9.4e-06, 'epoch': 1.0}                                                                                                  
{'loss': 1.2875, 'learning_rate': 9.377830188679246e-06, 'epoch': 1.0}                                                                                    
{'loss': 1.188, 'learning_rate': 9.35566037735849e-06, 'epoch': 1.01}                                                                                     
{'loss': 1.2893, 'learning_rate': 9.333490566037737e-06, 'epoch': 1.01}                                                                                   
{'loss': 1.0258, 'learning_rate': 9.311320754716981e-06, 'epoch': 1.02}                                                                                   
{'loss': 1.3352, 'learning_rate': 9.289150943396227e-06, 'epoch': 1.02}                                                                                   
{'loss': 1.0605, 'learning_rate': 9.266981132075472e-06, 'epoch': 1.03}                                                                                   
{'loss': 1.1707, 'learning_rate': 9.244811320754718e-06, 'epoch': 1.03}                                                                                   
{'loss': 1.1235, 'learning_rate': 9.222641509433962e-06, 'epoch': 1.04}                                                                                   
{'loss': 1.1178, 'learning_rate': 9.200471698113208e-06, 'epoch': 1.04}                                                                                   
{'loss': 1.1368, 'learning_rate': 9.178301886792453e-06, 'epoch': 1.04}                                                                                   
{'loss': 1.1672, 'learning_rate': 9.156132075471699e-06, 'epoch': 1.05}                                                                                   
{'loss': 1.3141, 'learning_rate': 9.133962264150943e-06, 'epoch': 1.05}                                                                                   
{'loss': 1.1222, 'learning_rate': 9.11179245283019e-06, 'epoch': 1.06}                                                                                    
{'loss': 1.251, 'learning_rate': 9.089622641509434e-06, 'epoch': 1.06}                                                                                    
{'loss': 1.1946, 'learning_rate': 9.06745283018868e-06, 'epoch': 1.07}                                                                                    
{'loss': 1.1905, 'learning_rate': 9.045283018867925e-06, 'epoch': 1.07}                                                                                   
{'loss': 1.0685, 'learning_rate': 9.02311320754717e-06, 'epoch': 1.08}                                                                                    
{'loss': 1.2852, 'learning_rate': 9.000943396226415e-06, 'epoch': 1.08}                                                                                   
{'loss': 0.9371, 'learning_rate': 8.978773584905661e-06, 'epoch': 1.09}                                                                                   
{'loss': 1.0912, 'learning_rate': 8.956603773584906e-06, 'epoch': 1.09}                                                                                   
{'loss': 1.1317, 'learning_rate': 8.934433962264152e-06, 'epoch': 1.1}                                                                                    
{'loss': 1.1203, 'learning_rate': 8.912264150943396e-06, 'epoch': 1.1}                                                                                    
{'loss': 0.9996, 'learning_rate': 8.890094339622643e-06, 'epoch': 1.11}                                                                                   
{'loss': 1.3056, 'learning_rate': 8.867924528301887e-06, 'epoch': 1.11}                                                                                   
{'loss': 0.9091, 'learning_rate': 8.845754716981133e-06, 'epoch': 1.12}                                                                                   
{'loss': 1.0645, 'learning_rate': 8.823584905660378e-06, 'epoch': 1.12}                                                                                   
{'loss': 1.0278, 'learning_rate': 8.801415094339624e-06, 'epoch': 1.12}                                                                                   
{'loss': 1.0527, 'learning_rate': 8.779245283018868e-06, 'epoch': 1.13}                                                                                   
{'loss': 1.2855, 'learning_rate': 8.757075471698114e-06, 'epoch': 1.13}                                                                                   
{'loss': 1.0167, 'learning_rate': 8.734905660377359e-06, 'epoch': 1.14}                                                                                   
{'loss': 1.1604, 'learning_rate': 8.712735849056605e-06, 'epoch': 1.14}                                                                                   
{'loss': 1.2128, 'learning_rate': 8.69056603773585e-06, 'epoch': 1.15}                                                                                    
{'loss': 0.9657, 'learning_rate': 8.668396226415096e-06, 'epoch': 1.15}                                                                                   
{'loss': 0.9309, 'learning_rate': 8.64622641509434e-06, 'epoch': 1.16}                                                                                    
{'loss': 1.3229, 'learning_rate': 8.624056603773586e-06, 'epoch': 1.16}                                                                                   
{'loss': 0.9728, 'learning_rate': 8.60188679245283e-06, 'epoch': 1.17}                                                                                    
{'loss': 1.1702, 'learning_rate': 8.579716981132077e-06, 'epoch': 1.17}                                                                                   
{'loss': 1.1717, 'learning_rate': 8.557547169811321e-06, 'epoch': 1.18}                                                                                   
{'loss': 1.0464, 'learning_rate': 8.535377358490567e-06, 'epoch': 1.18}                                                                                   
{'loss': 1.316, 'learning_rate': 8.513207547169812e-06, 'epoch': 1.19}                                                                                    
{'loss': 1.1708, 'learning_rate': 8.491037735849058e-06, 'epoch': 1.19}                                                                                   
{'loss': 1.0843, 'learning_rate': 8.468867924528303e-06, 'epoch': 1.2}                                                                                    
{'loss': 1.1671, 'learning_rate': 8.446698113207549e-06, 'epoch': 1.2}                                                                                    
{'loss': 0.7117, 'learning_rate': 8.424528301886793e-06, 'epoch': 1.2}                                                                                    
{'loss': 0.9852, 'learning_rate': 8.40235849056604e-06, 'epoch': 1.21}                                                                                    
{'loss': 1.0068, 'learning_rate': 8.380188679245284e-06, 'epoch': 1.21}                                                                                   
{'loss': 1.1698, 'learning_rate': 8.35801886792453e-06, 'epoch': 1.22}                                                                                    
{'loss': 0.8681, 'learning_rate': 8.335849056603774e-06, 'epoch': 1.22}                                                                                   
{'loss': 0.9566, 'learning_rate': 8.31367924528302e-06, 'epoch': 1.23}                                                                                    
{'loss': 0.8535, 'learning_rate': 8.291509433962265e-06, 'epoch': 1.23}                                                                                   
{'loss': 1.0659, 'learning_rate': 8.26933962264151e-06, 'epoch': 1.24}                                                                                    
{'loss': 0.9983, 'learning_rate': 8.247169811320756e-06, 'epoch': 1.24}                                                                                   
{'loss': 0.8578, 'learning_rate': 8.225e-06, 'epoch': 1.25}                                                                                               
{'loss': 1.1459, 'learning_rate': 8.202830188679246e-06, 'epoch': 1.25}                                                                                   
{'loss': 0.8953, 'learning_rate': 8.18066037735849e-06, 'epoch': 1.26}                                                                                    
{'loss': 1.1073, 'learning_rate': 8.158490566037735e-06, 'epoch': 1.26}                                                                                   
{'loss': 0.9207, 'learning_rate': 8.136320754716981e-06, 'epoch': 1.27}                                                                                   
{'loss': 0.906, 'learning_rate': 8.114150943396226e-06, 'epoch': 1.27}                                                                                    
{'loss': 1.0117, 'learning_rate': 8.091981132075472e-06, 'epoch': 1.28}                                                                                   
{'loss': 1.1474, 'learning_rate': 8.069811320754716e-06, 'epoch': 1.28}                                                                                   
{'loss': 0.9796, 'learning_rate': 8.047641509433962e-06, 'epoch': 1.28}                                                                                   
{'loss': 1.2722, 'learning_rate': 8.025471698113207e-06, 'epoch': 1.29}                                                                                   
{'loss': 1.1476, 'learning_rate': 8.003301886792453e-06, 'epoch': 1.29}                                                                                   
{'loss': 0.9096, 'learning_rate': 7.981132075471698e-06, 'epoch': 1.3}                                                                                    
{'loss': 1.2371, 'learning_rate': 7.958962264150944e-06, 'epoch': 1.3}                                                                                    
{'loss': 0.8844, 'learning_rate': 7.936792452830188e-06, 'epoch': 1.31}                                                                                   
{'loss': 0.9373, 'learning_rate': 7.914622641509434e-06, 'epoch': 1.31}                                                                                   
{'loss': 1.0129, 'learning_rate': 7.892452830188679e-06, 'epoch': 1.32}                                                                                   
{'loss': 0.8779, 'learning_rate': 7.870283018867925e-06, 'epoch': 1.32}                                                                                   
{'loss': 0.9774, 'learning_rate': 7.84811320754717e-06, 'epoch': 1.33}                                                                                    
{'loss': 1.1824, 'learning_rate': 7.825943396226415e-06, 'epoch': 1.33}                                                                                   
{'loss': 0.9323, 'learning_rate': 7.80377358490566e-06, 'epoch': 1.34}                                                                                    
{'loss': 1.0318, 'learning_rate': 7.781603773584906e-06, 'epoch': 1.34}                                                                                   
{'loss': 1.0116, 'learning_rate': 7.75943396226415e-06, 'epoch': 1.35}                                                                                    
{'loss': 0.8909, 'learning_rate': 7.737264150943397e-06, 'epoch': 1.35}                                                                                   
{'loss': 1.1998, 'learning_rate': 7.715094339622641e-06, 'epoch': 1.36}                                                                                   
{'loss': 1.017, 'learning_rate': 7.692924528301887e-06, 'epoch': 1.36}                                                                                    
{'loss': 0.9515, 'learning_rate': 7.670754716981132e-06, 'epoch': 1.36}                                                                                   
{'loss': 1.1653, 'learning_rate': 7.648584905660378e-06, 'epoch': 1.37}                                                                                   
{'loss': 0.6623, 'learning_rate': 7.626415094339623e-06, 'epoch': 1.37}                                                                                   
{'loss': 1.0602, 'learning_rate': 7.6042452830188685e-06, 'epoch': 1.38}                                                                                  
{'loss': 1.0556, 'learning_rate': 7.582075471698113e-06, 'epoch': 1.38}                                                                                   
{'loss': 1.1857, 'learning_rate': 7.559905660377359e-06, 'epoch': 1.39}                                                                                   
{'loss': 1.0944, 'learning_rate': 7.537735849056604e-06, 'epoch': 1.39}                                                                                   
{'loss': 0.8615, 'learning_rate': 7.51556603773585e-06, 'epoch': 1.4}                                                                                     
{'loss': 0.9978, 'learning_rate': 7.493396226415094e-06, 'epoch': 1.4}                                                                                    
{'loss': 0.9598, 'learning_rate': 7.47122641509434e-06, 'epoch': 1.41}                                                                                    
{'loss': 0.9763, 'learning_rate': 7.449056603773585e-06, 'epoch': 1.41}                                                                                   
 47%|██████████████████████████████████████████████████████▏                                                            | 300/636 [25:47<32:23,  5.78s/it]/home/josep/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/josep/miniconda3/envs/nlp/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
/home/josep/miniconda3/envs/nlp/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 0.9165, 'learning_rate': 7.426886792452831e-06, 'epoch': 1.42}                                                                                   
{'loss': 0.8293, 'learning_rate': 7.404716981132075e-06, 'epoch': 1.42}                                                                                   
{'loss': 1.0605, 'learning_rate': 7.3825471698113216e-06, 'epoch': 1.43}                                                                                  
{'loss': 0.9782, 'learning_rate': 7.360377358490566e-06, 'epoch': 1.43}                                                                                   
{'loss': 0.9508, 'learning_rate': 7.338207547169812e-06, 'epoch': 1.44}                                                                                   
{'loss': 1.0854, 'learning_rate': 7.316037735849057e-06, 'epoch': 1.44}                                                                                   
{'loss': 1.1066, 'learning_rate': 7.293867924528303e-06, 'epoch': 1.44}                                                                                   
{'loss': 1.036, 'learning_rate': 7.271698113207547e-06, 'epoch': 1.45}                                                                                    
{'loss': 0.947, 'learning_rate': 7.249528301886793e-06, 'epoch': 1.45}                                                                                    
{'loss': 0.9637, 'learning_rate': 7.227358490566038e-06, 'epoch': 1.46}                                                                                   
{'loss': 1.1157, 'learning_rate': 7.205188679245284e-06, 'epoch': 1.46}                                                                                   
{'loss': 1.2294, 'learning_rate': 7.1830188679245284e-06, 'epoch': 1.47}                                                                                  
{'loss': 1.1162, 'learning_rate': 7.160849056603775e-06, 'epoch': 1.47}                                                                                   
{'loss': 1.1629, 'learning_rate': 7.138679245283019e-06, 'epoch': 1.48}                                                                                   
{'loss': 0.724, 'learning_rate': 7.116509433962265e-06, 'epoch': 1.48}                                                                                    
{'loss': 1.1256, 'learning_rate': 7.09433962264151e-06, 'epoch': 1.49}                                                                                    
{'loss': 1.139, 'learning_rate': 7.072169811320756e-06, 'epoch': 1.49}                                                                                    
{'loss': 0.851, 'learning_rate': 7.05e-06, 'epoch': 1.5}                                                                                                  
{'loss': 0.839, 'learning_rate': 7.0278301886792456e-06, 'epoch': 1.5}                                                                                    
{'loss': 1.0918, 'learning_rate': 7.005660377358491e-06, 'epoch': 1.51}                                                                                   
{'loss': 1.0844, 'learning_rate': 6.983490566037736e-06, 'epoch': 1.51}                                                                                   
{'loss': 0.9574, 'learning_rate': 6.9613207547169815e-06, 'epoch': 1.52}                                                                                  
{'loss': 1.1085, 'learning_rate': 6.939150943396227e-06, 'epoch': 1.52}                                                                                   
{'loss': 1.1554, 'learning_rate': 6.916981132075472e-06, 'epoch': 1.52}                                                                                   
{'loss': 0.8646, 'learning_rate': 6.894811320754717e-06, 'epoch': 1.53}                                                                                   
{'loss': 0.827, 'learning_rate': 6.872641509433963e-06, 'epoch': 1.53}                                                                                    
{'loss': 1.0682, 'learning_rate': 6.850471698113208e-06, 'epoch': 1.54}                                                                                   
{'loss': 1.0566, 'learning_rate': 6.828301886792453e-06, 'epoch': 1.54}                                                                                   
{'loss': 0.8914, 'learning_rate': 6.806132075471699e-06, 'epoch': 1.55}                                                                                   
{'loss': 1.0294, 'learning_rate': 6.783962264150944e-06, 'epoch': 1.55}                                                                                   
{'loss': 0.9136, 'learning_rate': 6.761792452830189e-06, 'epoch': 1.56}                                                                                   
{'loss': 0.9151, 'learning_rate': 6.7396226415094345e-06, 'epoch': 1.56}                                                                                  
{'loss': 0.8387, 'learning_rate': 6.71745283018868e-06, 'epoch': 1.57}                                                                                    
{'loss': 0.8399, 'learning_rate': 6.695283018867925e-06, 'epoch': 1.57}                                                                                   
{'loss': 0.9477, 'learning_rate': 6.67311320754717e-06, 'epoch': 1.58}                                                                                    
{'loss': 0.8258, 'learning_rate': 6.650943396226416e-06, 'epoch': 1.58}                                                                                   
{'loss': 0.9355, 'learning_rate': 6.628773584905661e-06, 'epoch': 1.59}                                                                                   
{'loss': 0.9392, 'learning_rate': 6.606603773584906e-06, 'epoch': 1.59}                                                                                   
{'loss': 0.8508, 'learning_rate': 6.584433962264152e-06, 'epoch': 1.6}                                                                                    
{'loss': 0.9951, 'learning_rate': 6.562264150943397e-06, 'epoch': 1.6}                                                                                    
{'loss': 1.0752, 'learning_rate': 6.540094339622642e-06, 'epoch': 1.6}                                                                                    
{'loss': 0.9183, 'learning_rate': 6.5179245283018875e-06, 'epoch': 1.61}                                                                                  
{'loss': 0.9184, 'learning_rate': 6.495754716981133e-06, 'epoch': 1.61}                                                                                   
{'loss': 1.0672, 'learning_rate': 6.473584905660377e-06, 'epoch': 1.62}                                                                                   
{'loss': 1.0863, 'learning_rate': 6.451415094339623e-06, 'epoch': 1.62}                                                                                   
{'loss': 1.0354, 'learning_rate': 6.429245283018868e-06, 'epoch': 1.63}                                                                                   
{'loss': 0.9826, 'learning_rate': 6.407075471698113e-06, 'epoch': 1.63}                                                                                   
{'loss': 0.9182, 'learning_rate': 6.3849056603773585e-06, 'epoch': 1.64}                                                                                  
{'loss': 0.9627, 'learning_rate': 6.362735849056604e-06, 'epoch': 1.64}                                                                                   
{'loss': 1.2827, 'learning_rate': 6.340566037735849e-06, 'epoch': 1.65}                                                                                   
{'loss': 0.9699, 'learning_rate': 6.3183962264150944e-06, 'epoch': 1.65}                                                                                  
{'loss': 0.8898, 'learning_rate': 6.29622641509434e-06, 'epoch': 1.66}                                                                                    
{'loss': 1.0477, 'learning_rate': 6.274056603773585e-06, 'epoch': 1.66}                                                                                   
{'loss': 0.7515, 'learning_rate': 6.25188679245283e-06, 'epoch': 1.67}                                                                                    
{'loss': 1.0761, 'learning_rate': 6.229716981132076e-06, 'epoch': 1.67}                                                                                   
{'loss': 1.0347, 'learning_rate': 6.207547169811321e-06, 'epoch': 1.68}                                                                                   
{'loss': 1.1166, 'learning_rate': 6.185377358490566e-06, 'epoch': 1.68}                                                                                   
{'loss': 0.8263, 'learning_rate': 6.1632075471698116e-06, 'epoch': 1.68}                                                                                  
{'loss': 0.9055, 'learning_rate': 6.141037735849057e-06, 'epoch': 1.69}                                                                                   
{'loss': 0.9471, 'learning_rate': 6.118867924528302e-06, 'epoch': 1.69}                                                                                   
{'loss': 0.9324, 'learning_rate': 6.0966981132075475e-06, 'epoch': 1.7}                                                                                   
{'loss': 0.9573, 'learning_rate': 6.074528301886793e-06, 'epoch': 1.7}                                                                                    
{'loss': 0.9451, 'learning_rate': 6.052358490566038e-06, 'epoch': 1.71}                                                                                   
{'loss': 0.8763, 'learning_rate': 6.030188679245283e-06, 'epoch': 1.71}                                                                                   
{'loss': 1.1112, 'learning_rate': 6.008018867924529e-06, 'epoch': 1.72}                                                                                   
{'loss': 1.0139, 'learning_rate': 5.985849056603774e-06, 'epoch': 1.72}                                                                                   
{'loss': 0.9205, 'learning_rate': 5.963679245283019e-06, 'epoch': 1.73}                                                                                   
{'loss': 0.8918, 'learning_rate': 5.941509433962265e-06, 'epoch': 1.73}                                                                                   
{'loss': 0.8254, 'learning_rate': 5.91933962264151e-06, 'epoch': 1.74}                                                                                    
{'loss': 1.0425, 'learning_rate': 5.897169811320755e-06, 'epoch': 1.74}                                                                                   
{'loss': 0.9067, 'learning_rate': 5.8750000000000005e-06, 'epoch': 1.75}                                                                                  
{'loss': 0.8894, 'learning_rate': 5.852830188679246e-06, 'epoch': 1.75}                                                                                   
{'loss': 0.6195, 'learning_rate': 5.830660377358491e-06, 'epoch': 1.76}                                                                                   
{'loss': 0.974, 'learning_rate': 5.808490566037736e-06, 'epoch': 1.76}                                                                                    
{'loss': 0.8678, 'learning_rate': 5.786320754716982e-06, 'epoch': 1.76}                                                                                   
{'loss': 0.9349, 'learning_rate': 5.764150943396227e-06, 'epoch': 1.77}                                                                                   
{'loss': 0.7539, 'learning_rate': 5.741981132075472e-06, 'epoch': 1.77}                                                                                   
{'loss': 0.7834, 'learning_rate': 5.719811320754718e-06, 'epoch': 1.78}                                                                                   
{'loss': 1.0588, 'learning_rate': 5.697641509433963e-06, 'epoch': 1.78}                                                                                   
{'loss': 0.7346, 'learning_rate': 5.675471698113208e-06, 'epoch': 1.79}                                                                                   
{'loss': 0.9588, 'learning_rate': 5.6533018867924535e-06, 'epoch': 1.79}                                                                                  
{'loss': 1.14, 'learning_rate': 5.631132075471699e-06, 'epoch': 1.8}                                                                                      
{'loss': 1.0633, 'learning_rate': 5.608962264150944e-06, 'epoch': 1.8}                                                                                    
{'loss': 1.011, 'learning_rate': 5.5867924528301894e-06, 'epoch': 1.81}                                                                                   
{'loss': 0.917, 'learning_rate': 5.564622641509435e-06, 'epoch': 1.81}                                                                                    
{'loss': 1.0486, 'learning_rate': 5.54245283018868e-06, 'epoch': 1.82}                                                                                    
{'loss': 1.0221, 'learning_rate': 5.520283018867925e-06, 'epoch': 1.82}                                                                                   
{'loss': 0.9905, 'learning_rate': 5.498113207547171e-06, 'epoch': 1.83}                                                                                   
{'loss': 1.051, 'learning_rate': 5.475943396226416e-06, 'epoch': 1.83}                                                                                    
{'loss': 0.7195, 'learning_rate': 5.453773584905661e-06, 'epoch': 1.84}                                                                                   
{'loss': 1.0133, 'learning_rate': 5.4316037735849066e-06, 'epoch': 1.84}                                                                                  
{'loss': 1.0567, 'learning_rate': 5.409433962264152e-06, 'epoch': 1.84}                                                                                   
{'loss': 0.9333, 'learning_rate': 5.387264150943397e-06, 'epoch': 1.85}                                                                                   
{'loss': 1.0004, 'learning_rate': 5.3650943396226425e-06, 'epoch': 1.85}                                                                                  
{'loss': 0.8552, 'learning_rate': 5.342924528301888e-06, 'epoch': 1.86}                                                                                   
{'loss': 1.043, 'learning_rate': 5.320754716981132e-06, 'epoch': 1.86}                                                                                    
{'loss': 0.9447, 'learning_rate': 5.2985849056603775e-06, 'epoch': 1.87}                                                                                  
{'loss': 1.1422, 'learning_rate': 5.276415094339623e-06, 'epoch': 1.87}                                                                                   
{'loss': 1.0441, 'learning_rate': 5.254245283018868e-06, 'epoch': 1.88}                                                                                   
{'loss': 1.1155, 'learning_rate': 5.232075471698113e-06, 'epoch': 1.88}                                                                                   
 63%|████████████████████████████████████████████████████████████████████████▎                                          | 400/636 [34:23<24:03,  6.12s/it]/home/josep/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/josep/miniconda3/envs/nlp/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
/home/josep/miniconda3/envs/nlp/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 0.9788, 'learning_rate': 5.209905660377358e-06, 'epoch': 1.89}                                                                                   
{'loss': 0.8569, 'learning_rate': 5.187735849056603e-06, 'epoch': 1.89}                                                                                   
{'loss': 0.9463, 'learning_rate': 5.1655660377358485e-06, 'epoch': 1.9}                                                                                   
{'loss': 0.8742, 'learning_rate': 5.143396226415094e-06, 'epoch': 1.9}                                                                                    
{'loss': 0.8601, 'learning_rate': 5.121226415094339e-06, 'epoch': 1.91}                                                                                   
{'loss': 1.1198, 'learning_rate': 5.0990566037735844e-06, 'epoch': 1.91}                                                                                  
{'loss': 0.8072, 'learning_rate': 5.07688679245283e-06, 'epoch': 1.92}                                                                                    
{'loss': 0.8098, 'learning_rate': 5.054716981132075e-06, 'epoch': 1.92}                                                                                   
{'loss': 0.9234, 'learning_rate': 5.03254716981132e-06, 'epoch': 1.92}                                                                                    
{'loss': 1.0636, 'learning_rate': 5.010377358490566e-06, 'epoch': 1.93}                                                                                   
{'loss': 0.9531, 'learning_rate': 4.988207547169811e-06, 'epoch': 1.93}                                                                                   
{'loss': 0.912, 'learning_rate': 4.966037735849056e-06, 'epoch': 1.94}                                                                                    
{'loss': 0.7991, 'learning_rate': 4.9438679245283016e-06, 'epoch': 1.94}                                                                                  
{'loss': 0.7858, 'learning_rate': 4.921698113207547e-06, 'epoch': 1.95}                                                                                   
{'loss': 0.9156, 'learning_rate': 4.899528301886792e-06, 'epoch': 1.95}                                                                                   
{'loss': 1.0391, 'learning_rate': 4.8773584905660375e-06, 'epoch': 1.96}                                                                                  
{'loss': 0.8191, 'learning_rate': 4.855188679245283e-06, 'epoch': 1.96}                                                                                   
{'loss': 0.857, 'learning_rate': 4.833018867924528e-06, 'epoch': 1.97}                                                                                    
{'loss': 0.8543, 'learning_rate': 4.810849056603773e-06, 'epoch': 1.97}                                                                                   
{'loss': 0.854, 'learning_rate': 4.788679245283019e-06, 'epoch': 1.98}                                                                                    
{'loss': 0.9286, 'learning_rate': 4.766509433962264e-06, 'epoch': 1.98}                                                                                   
{'loss': 0.9784, 'learning_rate': 4.744339622641509e-06, 'epoch': 1.99}                                                                                   
{'loss': 0.9065, 'learning_rate': 4.722169811320755e-06, 'epoch': 1.99}                                                                                   
{'loss': 1.027, 'learning_rate': 4.7e-06, 'epoch': 2.0}                                                                                                   
{'loss': 0.8212, 'learning_rate': 4.677830188679245e-06, 'epoch': 2.0}                                                                                    
{'loss': 0.8607, 'learning_rate': 4.6556603773584905e-06, 'epoch': 2.0}                                                                                   
{'loss': 0.9557, 'learning_rate': 4.633490566037736e-06, 'epoch': 2.01}                                                                                   
{'loss': 0.7657, 'learning_rate': 4.611320754716981e-06, 'epoch': 2.01}                                                                                   
{'loss': 0.8144, 'learning_rate': 4.589150943396226e-06, 'epoch': 2.02}                                                                                   
{'loss': 0.9022, 'learning_rate': 4.566981132075472e-06, 'epoch': 2.02}                                                                                   
{'loss': 0.9119, 'learning_rate': 4.544811320754717e-06, 'epoch': 2.03}                                                                                   
{'loss': 1.1258, 'learning_rate': 4.522641509433962e-06, 'epoch': 2.03}                                                                                   
{'loss': 0.9265, 'learning_rate': 4.500471698113208e-06, 'epoch': 2.04}                                                                                   
{'loss': 0.574, 'learning_rate': 4.478301886792453e-06, 'epoch': 2.04}                                                                                    
{'loss': 0.9435, 'learning_rate': 4.456132075471698e-06, 'epoch': 2.05}                                                                                   
{'loss': 0.8164, 'learning_rate': 4.4339622641509435e-06, 'epoch': 2.05}                                                                                  
{'loss': 0.6653, 'learning_rate': 4.411792452830189e-06, 'epoch': 2.06}                                                                                   
{'loss': 0.8714, 'learning_rate': 4.389622641509434e-06, 'epoch': 2.06}                                                                                   
{'loss': 1.0226, 'learning_rate': 4.3674528301886794e-06, 'epoch': 2.07}                                                                                  
{'loss': 1.0519, 'learning_rate': 4.345283018867925e-06, 'epoch': 2.07}                                                                                   
{'loss': 0.9336, 'learning_rate': 4.32311320754717e-06, 'epoch': 2.08}                                                                                    
{'loss': 1.0574, 'learning_rate': 4.300943396226415e-06, 'epoch': 2.08}                                                                                   
{'loss': 0.671, 'learning_rate': 4.278773584905661e-06, 'epoch': 2.08}                                                                                    
{'loss': 0.6768, 'learning_rate': 4.256603773584906e-06, 'epoch': 2.09}                                                                                   
{'loss': 0.9739, 'learning_rate': 4.234433962264151e-06, 'epoch': 2.09}                                                                                   
{'loss': 0.731, 'learning_rate': 4.2122641509433966e-06, 'epoch': 2.1}                                                                                    
{'loss': 1.0556, 'learning_rate': 4.190094339622642e-06, 'epoch': 2.1}                                                                                    
{'loss': 1.1136, 'learning_rate': 4.167924528301887e-06, 'epoch': 2.11}                                                                                   
{'loss': 0.8036, 'learning_rate': 4.1457547169811325e-06, 'epoch': 2.11}                                                                                  
{'loss': 0.9698, 'learning_rate': 4.123584905660378e-06, 'epoch': 2.12}                                                                                   
{'loss': 0.8534, 'learning_rate': 4.101415094339623e-06, 'epoch': 2.12}                                                                                   
{'loss': 0.9461, 'learning_rate': 4.0792452830188675e-06, 'epoch': 2.13}                                                                                  
{'loss': 0.8421, 'learning_rate': 4.057075471698113e-06, 'epoch': 2.13}                                                                                   
{'loss': 0.8417, 'learning_rate': 4.034905660377358e-06, 'epoch': 2.14}                                                                                   
{'loss': 1.0037, 'learning_rate': 4.0127358490566035e-06, 'epoch': 2.14}                                                                                  
{'loss': 0.8487, 'learning_rate': 3.990566037735849e-06, 'epoch': 2.15}                                                                                   
{'loss': 0.9673, 'learning_rate': 3.968396226415094e-06, 'epoch': 2.15}                                                                                   
{'loss': 0.9076, 'learning_rate': 3.946226415094339e-06, 'epoch': 2.16}                                                                                   
{'loss': 1.0292, 'learning_rate': 3.924056603773585e-06, 'epoch': 2.16}                                                                                   
{'loss': 0.9502, 'learning_rate': 3.90188679245283e-06, 'epoch': 2.16}                                                                                    
{'loss': 0.7861, 'learning_rate': 3.879716981132075e-06, 'epoch': 2.17}                                                                                   
{'loss': 1.0717, 'learning_rate': 3.857547169811321e-06, 'epoch': 2.17}                                                                                   
{'loss': 0.8845, 'learning_rate': 3.835377358490566e-06, 'epoch': 2.18}                                                                                   
{'loss': 0.8402, 'learning_rate': 3.8132075471698116e-06, 'epoch': 2.18}                                                                                  
{'loss': 1.0282, 'learning_rate': 3.7910377358490565e-06, 'epoch': 2.19}                                                                                  
{'loss': 1.0333, 'learning_rate': 3.768867924528302e-06, 'epoch': 2.19}                                                                                   
{'loss': 1.0848, 'learning_rate': 3.746698113207547e-06, 'epoch': 2.2}                                                                                    
{'loss': 1.1009, 'learning_rate': 3.7245283018867924e-06, 'epoch': 2.2}                                                                                   
{'loss': 0.8293, 'learning_rate': 3.7023584905660377e-06, 'epoch': 2.21}                                                                                  
{'loss': 0.7316, 'learning_rate': 3.680188679245283e-06, 'epoch': 2.21}                                                                                   
{'loss': 0.7277, 'learning_rate': 3.6580188679245283e-06, 'epoch': 2.22}                                                                                  
{'loss': 0.9277, 'learning_rate': 3.6358490566037736e-06, 'epoch': 2.22}                                                                                  
{'loss': 0.824, 'learning_rate': 3.613679245283019e-06, 'epoch': 2.23}                                                                                    
{'loss': 0.8344, 'learning_rate': 3.5915094339622642e-06, 'epoch': 2.23}                                                                                  
{'loss': 0.8193, 'learning_rate': 3.5693396226415095e-06, 'epoch': 2.24}                                                                                  
{'loss': 0.9747, 'learning_rate': 3.547169811320755e-06, 'epoch': 2.24}                                                                                   
{'loss': 0.9932, 'learning_rate': 3.525e-06, 'epoch': 2.24}                                                                                               
{'loss': 0.9026, 'learning_rate': 3.5028301886792454e-06, 'epoch': 2.25}                                                                                  
{'loss': 0.9754, 'learning_rate': 3.4806603773584907e-06, 'epoch': 2.25}                                                                                  
{'loss': 1.0099, 'learning_rate': 3.458490566037736e-06, 'epoch': 2.26}                                                                                   
{'loss': 1.0504, 'learning_rate': 3.4363207547169813e-06, 'epoch': 2.26}                                                                                  
{'loss': 0.8599, 'learning_rate': 3.4141509433962266e-06, 'epoch': 2.27}                                                                                  
{'loss': 1.1678, 'learning_rate': 3.391981132075472e-06, 'epoch': 2.27}                                                                                   
{'loss': 0.8905, 'learning_rate': 3.3698113207547173e-06, 'epoch': 2.28}                                                                                  
{'loss': 0.7285, 'learning_rate': 3.3476415094339626e-06, 'epoch': 2.28}                                                                                  
{'loss': 1.0695, 'learning_rate': 3.325471698113208e-06, 'epoch': 2.29}                                                                                   
{'loss': 0.6647, 'learning_rate': 3.303301886792453e-06, 'epoch': 2.29}                                                                                   
{'loss': 0.9217, 'learning_rate': 3.2811320754716985e-06, 'epoch': 2.3}                                                                                   
{'loss': 0.8594, 'learning_rate': 3.2589622641509438e-06, 'epoch': 2.3}                                                                                   
{'loss': 0.8403, 'learning_rate': 3.2367924528301887e-06, 'epoch': 2.31}                                                                                  
{'loss': 0.8904, 'learning_rate': 3.214622641509434e-06, 'epoch': 2.31}                                                                                   
{'loss': 0.8703, 'learning_rate': 3.1924528301886793e-06, 'epoch': 2.32}                                                                                  
{'loss': 0.8541, 'learning_rate': 3.1702830188679246e-06, 'epoch': 2.32}                                                                                  
{'loss': 0.7575, 'learning_rate': 3.14811320754717e-06, 'epoch': 2.32}                                                                                    
{'loss': 0.8393, 'learning_rate': 3.125943396226415e-06, 'epoch': 2.33}                                                                                   
{'loss': 0.9151, 'learning_rate': 3.1037735849056605e-06, 'epoch': 2.33}                                                                                  
{'loss': 0.7138, 'learning_rate': 3.0816037735849058e-06, 'epoch': 2.34}                                                                                  
{'loss': 0.8382, 'learning_rate': 3.059433962264151e-06, 'epoch': 2.34}                                                                                   
{'loss': 1.0063, 'learning_rate': 3.0372641509433964e-06, 'epoch': 2.35}                                                                                  
{'loss': 0.8236, 'learning_rate': 3.0150943396226417e-06, 'epoch': 2.35}                                                                                  
 79%|██████████████████████████████████████████████████████████████████████████████████████████▍                        | 500/636 [42:56<10:34,  4.67s/it]/home/josep/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/josep/miniconda3/envs/nlp/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
/home/josep/miniconda3/envs/nlp/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 0.7692, 'learning_rate': 2.992924528301887e-06, 'epoch': 2.36}                                                                                   
{'loss': 0.9375, 'learning_rate': 2.9707547169811323e-06, 'epoch': 2.36}                                                                                  
{'loss': 0.8779, 'learning_rate': 2.9485849056603776e-06, 'epoch': 2.37}                                                                                  
{'loss': 0.9494, 'learning_rate': 2.926415094339623e-06, 'epoch': 2.37}                                                                                   
{'loss': 1.029, 'learning_rate': 2.904245283018868e-06, 'epoch': 2.38}                                                                                    
{'loss': 0.8312, 'learning_rate': 2.8820754716981135e-06, 'epoch': 2.38}                                                                                  
{'loss': 0.7203, 'learning_rate': 2.859905660377359e-06, 'epoch': 2.39}                                                                                   
{'loss': 0.7928, 'learning_rate': 2.837735849056604e-06, 'epoch': 2.39}                                                                                   
{'loss': 0.7677, 'learning_rate': 2.8155660377358494e-06, 'epoch': 2.4}                                                                                   
{'loss': 1.033, 'learning_rate': 2.7933962264150947e-06, 'epoch': 2.4}                                                                                    
{'loss': 0.6379, 'learning_rate': 2.77122641509434e-06, 'epoch': 2.4}                                                                                     
{'loss': 0.9679, 'learning_rate': 2.7490566037735853e-06, 'epoch': 2.41}                                                                                  
{'loss': 0.9599, 'learning_rate': 2.7268867924528306e-06, 'epoch': 2.41}                                                                                  
{'loss': 0.8708, 'learning_rate': 2.704716981132076e-06, 'epoch': 2.42}                                                                                   
{'loss': 0.9728, 'learning_rate': 2.6825471698113212e-06, 'epoch': 2.42}                                                                                  
{'loss': 0.8783, 'learning_rate': 2.660377358490566e-06, 'epoch': 2.43}                                                                                   
{'loss': 1.0147, 'learning_rate': 2.6382075471698114e-06, 'epoch': 2.43}                                                                                  
{'loss': 1.0662, 'learning_rate': 2.6160377358490563e-06, 'epoch': 2.44}                                                                                  
{'loss': 0.7572, 'learning_rate': 2.5938679245283016e-06, 'epoch': 2.44}                                                                                  
{'loss': 0.8973, 'learning_rate': 2.571698113207547e-06, 'epoch': 2.45}                                                                                   
{'loss': 1.0256, 'learning_rate': 2.5495283018867922e-06, 'epoch': 2.45}                                                                                  
{'loss': 0.8627, 'learning_rate': 2.5273584905660375e-06, 'epoch': 2.46}                                                                                  
{'loss': 0.9623, 'learning_rate': 2.505188679245283e-06, 'epoch': 2.46}                                                                                   
{'loss': 0.8403, 'learning_rate': 2.483018867924528e-06, 'epoch': 2.47}                                                                                   
{'loss': 0.9268, 'learning_rate': 2.4608490566037734e-06, 'epoch': 2.47}                                                                                  
{'loss': 0.761, 'learning_rate': 2.4386792452830187e-06, 'epoch': 2.48}                                                                                   
{'loss': 0.7838, 'learning_rate': 2.416509433962264e-06, 'epoch': 2.48}                                                                                   
{'loss': 1.0287, 'learning_rate': 2.3943396226415093e-06, 'epoch': 2.48}                                                                                  
{'loss': 1.0728, 'learning_rate': 2.3721698113207546e-06, 'epoch': 2.49}                                                                                  
{'loss': 0.8812, 'learning_rate': 2.35e-06, 'epoch': 2.49}                                                                                                
{'loss': 0.7911, 'learning_rate': 2.3278301886792453e-06, 'epoch': 2.5}                                                                                   
{'loss': 0.8751, 'learning_rate': 2.3056603773584906e-06, 'epoch': 2.5}                                                                                   
{'loss': 0.7333, 'learning_rate': 2.283490566037736e-06, 'epoch': 2.51}                                                                                   
{'loss': 1.0642, 'learning_rate': 2.261320754716981e-06, 'epoch': 2.51}                                                                                   
{'loss': 0.8445, 'learning_rate': 2.2391509433962265e-06, 'epoch': 2.52}                                                                                  
{'loss': 0.8379, 'learning_rate': 2.2169811320754718e-06, 'epoch': 2.52}                                                                                  
{'loss': 1.0705, 'learning_rate': 2.194811320754717e-06, 'epoch': 2.53}                                                                                   
{'loss': 0.7278, 'learning_rate': 2.1726415094339624e-06, 'epoch': 2.53}                                                                                  
{'loss': 1.0143, 'learning_rate': 2.1504716981132077e-06, 'epoch': 2.54}                                                                                  
{'loss': 1.0535, 'learning_rate': 2.128301886792453e-06, 'epoch': 2.54}                                                                                   
{'loss': 1.175, 'learning_rate': 2.1061320754716983e-06, 'epoch': 2.55}                                                                                   
{'loss': 1.1308, 'learning_rate': 2.0839622641509436e-06, 'epoch': 2.55}                                                                                  
{'loss': 1.0175, 'learning_rate': 2.061792452830189e-06, 'epoch': 2.56}                                                                                   
{'loss': 0.7421, 'learning_rate': 2.0396226415094338e-06, 'epoch': 2.56}                                                                                  
{'loss': 0.9001, 'learning_rate': 2.017452830188679e-06, 'epoch': 2.56}                                                                                   
{'loss': 0.9346, 'learning_rate': 1.9952830188679244e-06, 'epoch': 2.57}                                                                                  
{'loss': 0.846, 'learning_rate': 1.9731132075471697e-06, 'epoch': 2.57}                                                                                   
{'loss': 1.196, 'learning_rate': 1.950943396226415e-06, 'epoch': 2.58}                                                                                    
{'loss': 0.8088, 'learning_rate': 1.9287735849056603e-06, 'epoch': 2.58}                                                                                  
{'loss': 1.1764, 'learning_rate': 1.9066037735849058e-06, 'epoch': 2.59}                                                                                  
{'loss': 0.9433, 'learning_rate': 1.884433962264151e-06, 'epoch': 2.59}                                                                                   
{'loss': 0.872, 'learning_rate': 1.8622641509433962e-06, 'epoch': 2.6}                                                                                    
{'loss': 1.0711, 'learning_rate': 1.8400943396226415e-06, 'epoch': 2.6}                                                                                   
{'loss': 0.8501, 'learning_rate': 1.8179245283018868e-06, 'epoch': 2.61}                                                                                  
{'loss': 0.7825, 'learning_rate': 1.7957547169811321e-06, 'epoch': 2.61}                                                                                  
{'loss': 0.9689, 'learning_rate': 1.7735849056603774e-06, 'epoch': 2.62}                                                                                  
{'loss': 0.9788, 'learning_rate': 1.7514150943396227e-06, 'epoch': 2.62}                                                                                  
{'loss': 1.0371, 'learning_rate': 1.729245283018868e-06, 'epoch': 2.63}                                                                                   
{'loss': 0.9213, 'learning_rate': 1.7070754716981133e-06, 'epoch': 2.63}                                                                                  
{'loss': 0.8118, 'learning_rate': 1.6849056603773586e-06, 'epoch': 2.64}                                                                                  
{'loss': 0.9448, 'learning_rate': 1.662735849056604e-06, 'epoch': 2.64}                                                                                   
{'loss': 1.0785, 'learning_rate': 1.6405660377358492e-06, 'epoch': 2.64}                                                                                  
{'loss': 0.7159, 'learning_rate': 1.6183962264150943e-06, 'epoch': 2.65}                                                                                  
{'loss': 0.8911, 'learning_rate': 1.5962264150943396e-06, 'epoch': 2.65}                                                                                  
{'loss': 0.8676, 'learning_rate': 1.574056603773585e-06, 'epoch': 2.66}                                                                                   
{'loss': 0.7764, 'learning_rate': 1.5518867924528302e-06, 'epoch': 2.66}                                                                                  
{'loss': 0.9868, 'learning_rate': 1.5297169811320755e-06, 'epoch': 2.67}                                                                                  
{'loss': 0.9116, 'learning_rate': 1.5075471698113208e-06, 'epoch': 2.67}                                                                                  
{'loss': 1.0243, 'learning_rate': 1.4853773584905661e-06, 'epoch': 2.68}                                                                                  
{'loss': 1.0921, 'learning_rate': 1.4632075471698115e-06, 'epoch': 2.68}                                                                                  
{'loss': 0.8058, 'learning_rate': 1.4410377358490568e-06, 'epoch': 2.69}                                                                                  
{'loss': 0.5899, 'learning_rate': 1.418867924528302e-06, 'epoch': 2.69}                                                                                   
{'loss': 0.9455, 'learning_rate': 1.3966981132075474e-06, 'epoch': 2.7}                                                                                   
{'loss': 0.9586, 'learning_rate': 1.3745283018867927e-06, 'epoch': 2.7}                                                                                   
{'loss': 1.0544, 'learning_rate': 1.352358490566038e-06, 'epoch': 2.71}                                                                                   
{'loss': 0.7421, 'learning_rate': 1.330188679245283e-06, 'epoch': 2.71}                                                                                   
{'loss': 0.9165, 'learning_rate': 1.3080188679245282e-06, 'epoch': 2.72}                                                                                  
{'loss': 0.7568, 'learning_rate': 1.2858490566037735e-06, 'epoch': 2.72}                                                                                  
{'loss': 1.0068, 'learning_rate': 1.2636792452830188e-06, 'epoch': 2.72}                                                                                  
{'loss': 1.0263, 'learning_rate': 1.241509433962264e-06, 'epoch': 2.73}                                                                                   
{'loss': 1.0552, 'learning_rate': 1.2193396226415094e-06, 'epoch': 2.73}                                                                                  
{'loss': 0.9126, 'learning_rate': 1.1971698113207547e-06, 'epoch': 2.74}                                                                                  
{'loss': 0.8424, 'learning_rate': 1.175e-06, 'epoch': 2.74}                                                                                               
{'loss': 0.8263, 'learning_rate': 1.1528301886792453e-06, 'epoch': 2.75}                                                                                  
{'loss': 0.9611, 'learning_rate': 1.1306603773584906e-06, 'epoch': 2.75}                                                                                  
{'loss': 1.0088, 'learning_rate': 1.1084905660377359e-06, 'epoch': 2.76}                                                                                  
{'loss': 0.8783, 'learning_rate': 1.0863207547169812e-06, 'epoch': 2.76}                                                                                  
{'loss': 1.1189, 'learning_rate': 1.0641509433962265e-06, 'epoch': 2.77}                                                                                  
{'loss': 0.7794, 'learning_rate': 1.0419811320754718e-06, 'epoch': 2.77}                                                                                  
{'loss': 0.9081, 'learning_rate': 1.0198113207547169e-06, 'epoch': 2.78}                                                                                  
{'loss': 1.0236, 'learning_rate': 9.976415094339622e-07, 'epoch': 2.78}                                                                                   
{'loss': 0.9015, 'learning_rate': 9.754716981132075e-07, 'epoch': 2.79}                                                                                   
{'loss': 0.955, 'learning_rate': 9.533018867924529e-07, 'epoch': 2.79}                                                                                    
{'loss': 1.0149, 'learning_rate': 9.311320754716981e-07, 'epoch': 2.8}                                                                                    
{'loss': 0.7943, 'learning_rate': 9.089622641509434e-07, 'epoch': 2.8}                                                                                    
{'loss': 0.8213, 'learning_rate': 8.867924528301887e-07, 'epoch': 2.8}                                                                                    
{'loss': 0.9442, 'learning_rate': 8.64622641509434e-07, 'epoch': 2.81}                                                                                    
{'loss': 0.6224, 'learning_rate': 8.424528301886793e-07, 'epoch': 2.81}                                                                                   
{'loss': 0.7379, 'learning_rate': 8.202830188679246e-07, 'epoch': 2.82}                                                                                   
{'loss': 0.8471, 'learning_rate': 7.981132075471698e-07, 'epoch': 2.82}                                                                                   
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▍      | 600/636 [51:18<02:50,  4.74s/it]/home/josep/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/josep/miniconda3/envs/nlp/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
/home/josep/miniconda3/envs/nlp/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
{'loss': 0.9535, 'learning_rate': 7.759433962264151e-07, 'epoch': 2.83}                                                                                   
{'loss': 0.7379, 'learning_rate': 7.537735849056604e-07, 'epoch': 2.83}                                                                                   
{'loss': 0.9548, 'learning_rate': 7.316037735849057e-07, 'epoch': 2.84}                                                                                   
{'loss': 1.1167, 'learning_rate': 7.09433962264151e-07, 'epoch': 2.84}                                                                                    
{'loss': 0.9052, 'learning_rate': 6.872641509433963e-07, 'epoch': 2.85}                                                                                   
{'loss': 0.6535, 'learning_rate': 6.650943396226415e-07, 'epoch': 2.85}                                                                                   
{'loss': 0.8352, 'learning_rate': 6.429245283018867e-07, 'epoch': 2.86}                                                                                   
{'loss': 0.839, 'learning_rate': 6.20754716981132e-07, 'epoch': 2.86}                                                                                     
{'loss': 1.1124, 'learning_rate': 5.985849056603773e-07, 'epoch': 2.87}                                                                                   
{'loss': 1.0892, 'learning_rate': 5.764150943396226e-07, 'epoch': 2.87}                                                                                   
{'loss': 1.0238, 'learning_rate': 5.542452830188679e-07, 'epoch': 2.88}                                                                                   
{'loss': 1.0299, 'learning_rate': 5.320754716981132e-07, 'epoch': 2.88}                                                                                   
{'loss': 0.983, 'learning_rate': 5.099056603773584e-07, 'epoch': 2.88}                                                                                    
{'loss': 0.9269, 'learning_rate': 4.877358490566037e-07, 'epoch': 2.89}                                                                                   
{'loss': 0.8636, 'learning_rate': 4.6556603773584905e-07, 'epoch': 2.89}                                                                                  
{'loss': 0.7376, 'learning_rate': 4.4339622641509435e-07, 'epoch': 2.9}                                                                                   
{'loss': 0.9799, 'learning_rate': 4.2122641509433966e-07, 'epoch': 2.9}                                                                                   
{'loss': 1.0785, 'learning_rate': 3.990566037735849e-07, 'epoch': 2.91}                                                                                   
{'loss': 1.0076, 'learning_rate': 3.768867924528302e-07, 'epoch': 2.91}                                                                                   
{'loss': 0.7944, 'learning_rate': 3.547169811320755e-07, 'epoch': 2.92}                                                                                   
{'loss': 0.8707, 'learning_rate': 3.3254716981132077e-07, 'epoch': 2.92}                                                                                  
{'loss': 0.8609, 'learning_rate': 3.10377358490566e-07, 'epoch': 2.93}                                                                                    
{'loss': 1.0257, 'learning_rate': 2.882075471698113e-07, 'epoch': 2.93}                                                                                   
{'loss': 1.0391, 'learning_rate': 2.660377358490566e-07, 'epoch': 2.94}                                                                                   
{'loss': 0.9164, 'learning_rate': 2.4386792452830187e-07, 'epoch': 2.94}                                                                                  
{'loss': 0.7876, 'learning_rate': 2.2169811320754718e-07, 'epoch': 2.95}                                                                                  
{'loss': 0.8713, 'learning_rate': 1.9952830188679245e-07, 'epoch': 2.95}                                                                                  
{'loss': 0.6644, 'learning_rate': 1.7735849056603776e-07, 'epoch': 2.96}                                                                                  
{'loss': 1.0217, 'learning_rate': 1.55188679245283e-07, 'epoch': 2.96}                                                                                    
{'loss': 0.7107, 'learning_rate': 1.330188679245283e-07, 'epoch': 2.96}                                                                                   
{'loss': 0.8676, 'learning_rate': 1.1084905660377359e-07, 'epoch': 2.97}                                                                                  
{'loss': 0.9005, 'learning_rate': 8.867924528301888e-08, 'epoch': 2.97}                                                                                   
{'loss': 0.9418, 'learning_rate': 6.650943396226416e-08, 'epoch': 2.98}                                                                                   
{'loss': 0.8392, 'learning_rate': 4.433962264150944e-08, 'epoch': 2.98}                                                                                   
{'loss': 1.0358, 'learning_rate': 2.216981132075472e-08, 'epoch': 2.99}                                                                                   
{'loss': 0.9377, 'learning_rate': 0.0, 'epoch': 2.99}                                                                                                     
{'train_runtime': 3273.8564, 'train_samples_per_second': 1.558, 'train_steps_per_second': 0.194, 'train_loss': 1.1841015440862883, 'epoch': 2.99}         
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 636/636 [54:33<00:00,  5.15s/it]
